{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconnaissance d'images avec TensorFlow\n",
    "Ce notebook décrit de la reconnaissance d'images avec un modèle de convolution (CNN) sur TensorFlow.\n",
    "Il est inspiré d'un [Tutorial Tensorflow](https://www.tensorflow.org/tutorials/layers).\n",
    "\n",
    "Le but est d'apprendre à reconnaitre des chiffres écrits à la main sous forme d'image mono-chrome (de taille 28x28).\n",
    "Il s'agit des données [MNIST](http://yann.lecun.com/exdb/mnist/)\n",
    "\n",
    "## Exemples:\n",
    "<img align=\"left\" src=\"mnist_plot.png\" width=\"400\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import des librairies\n",
    "En particulier Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Définition du modele\n",
    "Il est basé sur un modèle d'apprentissage profond avec plusieurs couches:\n",
    "* Couche d'entrée (28x28x1)\n",
    "* Couches de Convolution (CNN)\n",
    "* Couches de Max_pooling\n",
    "* Couche de réseau de neurones dense \n",
    "* Couche de sortie correspondant aux 10 chiffres (0 à 9) à classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "\n",
    "def cnn_model_fn(features, labels, mode):\n",
    "  \"\"\"Model function for CNN.\"\"\"\n",
    "  # Input Layer\n",
    "  # Reshape X to 4-D tensor: [batch_size, width, height, channels]\n",
    "  # MNIST images are 28x28 pixels, and have one color channel\n",
    "  input_layer = tf.reshape(features[\"x\"], [-1, 28, 28, 1])\n",
    "\n",
    "  # Convolutional Layer #1\n",
    "  # Computes 32 features using a 5x5 filter with ReLU activation.\n",
    "  # Padding is added to preserve width and height.\n",
    "  # Input Tensor Shape: [batch_size, 28, 28, 1]\n",
    "  # Output Tensor Shape: [batch_size, 28, 28, 32]\n",
    "  conv1 = tf.layers.conv2d(\n",
    "      inputs=input_layer,\n",
    "      filters=32,\n",
    "      kernel_size=[5, 5],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "\n",
    "  # Pooling Layer #1\n",
    "  # First max pooling layer with a 2x2 filter and stride of 2\n",
    "  # Input Tensor Shape: [batch_size, 28, 28, 32]\n",
    "  # Output Tensor Shape: [batch_size, 14, 14, 32]\n",
    "  pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "\n",
    "  # Convolutional Layer #2\n",
    "  # Computes 64 features using a 5x5 filter.\n",
    "  # Padding is added to preserve width and height.\n",
    "  # Input Tensor Shape: [batch_size, 14, 14, 32]\n",
    "  # Output Tensor Shape: [batch_size, 14, 14, 64]\n",
    "  conv2 = tf.layers.conv2d(\n",
    "      inputs=pool1,\n",
    "      filters=64,\n",
    "      kernel_size=[5, 5],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "\n",
    "  # Pooling Layer #2\n",
    "  # Second max pooling layer with a 2x2 filter and stride of 2\n",
    "  # Input Tensor Shape: [batch_size, 14, 14, 64]\n",
    "  # Output Tensor Shape: [batch_size, 7, 7, 64]\n",
    "  pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "\n",
    "  # Flatten tensor into a batch of vectors\n",
    "  # Input Tensor Shape: [batch_size, 7, 7, 64]\n",
    "  # Output Tensor Shape: [batch_size, 7 * 7 * 64]\n",
    "  pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\n",
    "\n",
    "  # Dense Layer\n",
    "  # Densely connected layer with 1024 neurons\n",
    "  # Input Tensor Shape: [batch_size, 7 * 7 * 64]\n",
    "  # Output Tensor Shape: [batch_size, 1024]\n",
    "  dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n",
    "\n",
    "  # Add dropout operation; 0.6 probability that element will be kept\n",
    "  dropout = tf.layers.dropout(\n",
    "      inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "  # Logits layer\n",
    "  # Input Tensor Shape: [batch_size, 1024]\n",
    "  # Output Tensor Shape: [batch_size, 10]\n",
    "  logits = tf.layers.dense(inputs=dropout, units=10)\n",
    "\n",
    "  predictions = {\n",
    "      # Generate predictions (for PREDICT and EVAL mode)\n",
    "      \"classes\": tf.argmax(input=logits, axis=1),\n",
    "      # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n",
    "      # `logging_hook`.\n",
    "      \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "  }\n",
    "  if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "  # Calculate Loss (for both TRAIN and EVAL modes)\n",
    "  loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "\n",
    "  # Configure the Training Op (for TRAIN mode)\n",
    "  if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "    train_op = optimizer.minimize(\n",
    "        loss=loss,\n",
    "        global_step=tf.train.get_global_step())\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "  # Add evaluation metrics (for EVAL mode)\n",
    "  eval_metric_ops = {\n",
    "      \"accuracy\": tf.metrics.accuracy(\n",
    "          labels=labels, predictions=predictions[\"classes\"])}\n",
    "  return tf.estimator.EstimatorSpec(\n",
    "      mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des données d'apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST-data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST-data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Load training and eval data\n",
    "mnist = tf.contrib.learn.datasets.load_dataset(\"mnist\")\n",
    "train_data = mnist.train.images  # Returns np.array\n",
    "train_labels = np.asarray(mnist.train.labels, dtype=np.int32)\n",
    "eval_data = mnist.test.images  # Returns np.array\n",
    "eval_labels = np.asarray(mnist.test.labels, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: (55000, 784)\n",
      "Test data: (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train data:\",train_data.shape)\n",
    "print(\"Test data:\",eval_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création et entrainement de l'estimateur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '.', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001C32ADF1C18>, '_task_type': 'worker', '_task_id': 0, '_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "mnist_classifier = tf.estimator.Estimator(model_fn=cnn_model_fn, model_dir=\".\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging for predictions\n",
    "# Log the values in the \"Softmax\" tensor with label \"probabilities\"\n",
    "#tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n",
    "tensors_to_log = {}\n",
    "logging_hook = tf.train.LoggingTensorHook(\n",
    "    tensors=tensors_to_log, every_n_iter=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from .\\model.ckpt-4201\n",
      "INFO:tensorflow:Saving checkpoints for 4202 into .\\model.ckpt.\n",
      "INFO:tensorflow:\n",
      "INFO:tensorflow:loss = 0.5716102, step = 4202\n",
      "INFO:tensorflow:global_step/sec: 20.1892\n",
      "INFO:tensorflow:loss = 0.44799381, step = 4302 (5.002 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.0916\n",
      "INFO:tensorflow: (9.932 sec)\n",
      "INFO:tensorflow:loss = 0.4730778, step = 4402 (4.930 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.3038\n",
      "INFO:tensorflow:loss = 0.34859753, step = 4502 (4.926 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.2928\n",
      "INFO:tensorflow: (9.852 sec)\n",
      "INFO:tensorflow:loss = 0.21437319, step = 4602 (4.926 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.2528\n",
      "INFO:tensorflow:loss = 0.453292, step = 4702 (4.938 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.2801\n",
      "INFO:tensorflow: (9.869 sec)\n",
      "INFO:tensorflow:loss = 0.2673164, step = 4802 (4.932 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.3404\n",
      "INFO:tensorflow:loss = 0.33983114, step = 4902 (4.914 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.3066\n",
      "INFO:tensorflow: (9.842 sec)\n",
      "INFO:tensorflow:loss = 0.2949971, step = 5002 (4.927 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.1701\n",
      "INFO:tensorflow:loss = 0.30292958, step = 5102 (4.957 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.271\n",
      "INFO:tensorflow: (9.891 sec)\n",
      "INFO:tensorflow:loss = 0.37006867, step = 5202 (4.934 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.249\n",
      "INFO:tensorflow:loss = 0.2756146, step = 5302 (4.936 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.2153\n",
      "INFO:tensorflow: (9.884 sec)\n",
      "INFO:tensorflow:loss = 0.40096155, step = 5402 (4.949 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.1323\n",
      "INFO:tensorflow:loss = 0.41905624, step = 5502 (4.966 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.2721\n",
      "INFO:tensorflow: (9.903 sec)\n",
      "INFO:tensorflow:loss = 0.28006956, step = 5602 (4.936 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.2758\n",
      "INFO:tensorflow:loss = 0.18126293, step = 5702 (4.928 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.27\n",
      "INFO:tensorflow: (9.863 sec)\n",
      "INFO:tensorflow:loss = 0.1933515, step = 5802 (4.935 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.2612\n",
      "INFO:tensorflow:loss = 0.19969375, step = 5902 (4.935 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.2931\n",
      "INFO:tensorflow: (9.864 sec)\n",
      "INFO:tensorflow:loss = 0.29793125, step = 6002 (4.929 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.2845\n",
      "INFO:tensorflow:loss = 0.27839965, step = 6102 (4.928 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6201 into .\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.22104329.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x1c32adf14a8>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": train_data},\n",
    "    y=train_labels,\n",
    "    batch_size=100,\n",
    "    num_epochs=None,\n",
    "    shuffle=True)\n",
    "\n",
    "mnist_classifier.train(\n",
    "    input_fn=train_input_fn,\n",
    "    steps=2000,\n",
    "    hooks=[logging_hook])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation sur les données de test\n",
    "On évalue le modèle préalablement entrainé sur les données de test pour verifier la justesse de la prédiction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2018-02-19-16:43:03\n",
      "INFO:tensorflow:Restoring parameters from .\\model.ckpt-6201\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-19-16:43:05\n",
      "INFO:tensorflow:Saving dict for global step 6201: accuracy = 0.9352, global_step = 6201, loss = 0.22914135\n",
      "Résultats de l'évaluation: {'accuracy': 0.9352, 'loss': 0.22914135, 'global_step': 6201}\n"
     ]
    }
   ],
   "source": [
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": eval_data},\n",
    "    y=eval_labels,\n",
    "    num_epochs=1,\n",
    "    shuffle=False)\n",
    "\n",
    "eval_results = mnist_classifier.evaluate(input_fn=eval_input_fn)\n",
    "print(\"Résultats de l'évaluation:\",eval_results)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Conclusion\n",
    "L'exactitude des prédictions dépend du nombre d'itérations lors de l'apprentissage \n",
    "(on utilise la méthode du gradient stochastique pour optimiser les paramètres du modèle).\n",
    "\n",
    "Avec un peu de patience, on peut atteindre une precision de plus de 97%!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
